#! /bin/bash
#SBATCH --account=brazelton
#SBATCH --partition=lonepeak
#SBATCH --ntasks 12

module use $HOME/MyModules
module load miniconda3/latest
source /uufs/chpc.utah.edu/common/home/u0885949/software/pkg/miniconda3/etc/profile.d/conda.sh

export PATH=$PATH:/uufs/chpc.utah.edu/common/home/u0885949/software/bbtools/bbmap/

# define paths:
# 1. qc-trimmed and -filtered reads
QCREADS_PATH="qc_reads"
ADAPTERS="truseq_adapters.fa"
PHIX="phix174.fa.gz"
# 2. path to database downloaded with amrfinder -u
DB="/scratch/general/vast/u0885949/amrfinder_db/2024-07-22.1"
# 3. gff file generated by prodigal for each assembly
GFF_PATH="gff_files"
# 4. amrfinder results generated for each assembly
AMR_PATH="amrfinder_results"
# 5. dereplicated bam files and their index files representing reads mapped back to their assembly
BAM_PATH="bam_files"
# 6. scripts required for the workflow
SCRIPTS_PATH="scripts"

# qc reads with bbduk and fastp
conda activate fastp
for FORWARD in *_L001_R1_001.fastq.gz
do
sample=$(basename $FORWARD _L001_R1_001.fastq.gz)
bbduk.sh -Xmx10g ziplevel=9 threads=16 qin=33 ref=$ADAPTERS in1=${sample}_L001_R1_001.fastq.gz in2=${sample}_L001_R2_001.fastq.gz out=${sample}.interleaved.atrim.fq.gz stats=${sample}.adapter_stats.txt ftm=5 ktrim=r k=23 mink=9 rcomp=t hdist=2 tbo tpe minlength=0 2>${sample}.adapters.log
bbduk.sh -Xmx10g threads=16 qin=33 interleaved=t ref=$PHIX in=${sample}.interleaved.atrim.fq.gz out=${sample}.interleaved.atrim.nophix.fq.gz outm=${sample}.phix.fq.gz k=31 hdist=1 mcf=0.9 stats=${sample}.phix_stats.txt 2>${sample}.phix.log
fastp --thread 12 --cut_front --cut_window_size 8 --cut_mean_quality 28 --interleaved_in -i ${sample}.interleaved.atrim.nophix.fq.gz -h ${sample}.fastp.html -j ${sample}.fastp.json --out1 ${sample}.forward.atrim.nophix.fastp.fq.gz --out2 ${sample}.reverse.atrim.nophix.fastp.fq.gz
done

# delete intermediate files
rm *.atrim.fq.gz
rm *.atrim.nophix.fq.gz
rm *.phix.fq.gz

# move other files to qc_reads
mkdir $QCREADS_PATH
mv *.html "$QCREADS_PATH"/
mv *.json "$QCREADS_PATH"/
mv *.log "$QCREADS_PATH"/
mv *.txt "$QCREADS_PATH"/

# assembly with Megahit
conda activate megahit
for READS in *.forward.atrim.nophix.fastp.fq.gz
do
ASS=$(basename $READS .forward.atrim.nophix.fastp.fq.gz)
echo "writing assembly to" "$ASS"_megahit
# no singles
megahit -t 12 -m 0.9 -1 "$ASS".forward.atrim.nophix.fastp.fq.gz -2 "$ASS".reverse.atrim.nophix.fastp.fq.gz --out-prefix $ASS --out-dir "$ASS"_megahit --min-contig-len 400 --k-min 27 --k-max 151 --k-step 4
done

# rename contigs
mkdir "$GFF_PATH"
conda activate bioawk
for ASS in *_megahit/*.contigs.fa
do
	BASE=$(basename $ASS .contigs.fa)
	bioawk -c fastx '{ print ">scaffold-" ++i"_"length($seq)"\n"$seq }' < $ASS > "$BASE".renamed.fa
	paste <(grep ">" $ASS) <(grep ">" "$BASE".renamed.fa) | sed 's/>//g' > "$BASE"-old-names-new-names.tsv
done

# prodigal and cleanup
conda activate prodigal
for ASS in *.renamed.fa
do
	BASE=$(basename $ASS .renamed.fa)
	prodigal -q -p meta -f gff -i $BASE.renamed.fa -o $BASE.gff -a $BASE.faa -d $BASE.ffn 
	awk '/^>/{split($0, a, " "); print a[1]; next} {gsub(/[-\*_\.]/,""); print}' $BASE.faa > $BASE.faa.clean
	sed -i 's/\x0//g' $BASE.faa.clean
	mv $BASE.faa.clean $BASE.faa
	awk -F'\t' '/^#/{print $0; next} {sub(/ID\=[^_]*_/, "ID="$1"_", $9); print $1"\t"$2"\t"$3"\t"$4"\t"$5"\t"$6"\t"$7"\t"$8"\t"$9}' $BASE.gff > $BASE.gff.clean
	mv $BASE.gff.clean $BASE.gff
	mv $BASE.faa "$GFF_PATH"/$BASE.faa
	mv $BASE.gff "$GFF_PATH"/$BASE.gff
	mv $BASE.ffn "$GFF_PATH"/$BASE.ffn
done

# amrfinder
conda activate amrfinder
for ASS in "$GFF_PATH"/*.faa
do
	BASE=$(basename $ASS .faa)
	amrfinder --protein $ASS --plus --database $DB -o "$BASE".amrfinder.tsv --threads 12 > amrfinder-log-"$BASE".txt
done

# get contig coverages with coverm
conda activate coverm
for ASS in *.renamed.fa
do
	BASE=$(basename $ASS .renamed.fa)
	coverm contig -1 "$BASE".forward.atrim.nophix.fastp.fq.gz -2 "$BASE".reverse.atrim.nophix.fastp.fq.gz -m tpm -r $ASS -o "$BASE".coverm.tsv -t 12 -v
done

conda activate pandas
for ASS in *.renamed.fa
do
	BASE=$(basename $ASS .renamed.fa)
	"$SCRIPTS_PATH"/amrfinder-contig-covs.py -a "$BASE".amrfinder.tsv -c "$BASE".coverm.tsv
done

# merge all .amrfinder.contig_covs.csv tables
"$SCRIPTS_PATH"/merge-amrfinder-tables.py

# clean up files
mv *.fastp.fq.gz "$QCREADS_PATH"

mkdir "$AMR_PATH"
mv *.amrfinder.contig_covs.csv "$AMR_PATH"/
mv *.coverm.tsv "$AMR_PATH"/
mv amrfinder-log* "$AMR_PATH"/
